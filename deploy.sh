#!/usr/bin/env bash
# deploy.sh — wrapper around `databricks bundle deploy`
#
# Usage:  ./deploy.sh [--target <target>] [other bundle flags]
#
# Databricks Apps uploads app/app.yaml as-is without bundle variable substitution,
# so CATALOG / SCHEMA / PGDATABASE cannot use ${var.*} in that file. This script
# resolves those values from `bundle validate`, writes app/_bundle_config.py with
# the actual values, then runs the deploy. The app imports _bundle_config.py at
# startup to get the correct catalog and schema names.
#
# app/_bundle_config.py is gitignored and re-generated on every deploy.

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BUNDLE_ARGS=("$@")

echo "==> Resolving bundle variables..."
VALIDATE_JSON=$(databricks bundle validate --output json "${BUNDLE_ARGS[@]}" 2>/dev/null)

CATALOG=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('catalog',{}).get('value','my_catalog'))")
SCHEMA=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('schema',{}).get('value','actuarial_workshop'))")
PG_DATABASE=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('pg_database',{}).get('value','actuarial_workshop_db'))")

echo "==> Generating app/_bundle_config.py"
echo "    CATALOG=${CATALOG}, SCHEMA=${SCHEMA}, PG_DATABASE=${PG_DATABASE}"
cat > "${SCRIPT_DIR}/app/_bundle_config.py" << EOF
# Auto-generated by deploy.sh — do not edit or commit
CATALOG = '${CATALOG}'
SCHEMA = '${SCHEMA}'
PG_DATABASE = '${PG_DATABASE}'
EOF

echo "==> Running databricks bundle deploy ${BUNDLE_ARGS[*]}"
databricks bundle deploy "${BUNDLE_ARGS[@]}"
