#!/usr/bin/env bash
# deploy.sh — full end-to-end deploy: bundle + setup job + app
#
# Usage:  ./deploy.sh [--target <target>] [other bundle flags]
#
# Sequence
# --------
#   1. Resolve bundle variables via `bundle validate`; generate app/_bundle_config.py
#      (app/app.yaml is uploaded as source and does not receive DAB variable
#      substitution, so catalog/schema/pg_database are injected via this file).
#   2. `databricks bundle deploy` — provisions all bundle-managed resources
#      (Lakebase instance, jobs, DLT pipeline, app resource).
#   3. If a fresh app was created with compute STOPPED, call `apps start` to
#      start the compute and clear the bundle's initial-deployment lock.
#   4. `databricks bundle run actuarial_workshop_setup` — runs the setup job,
#      which seeds the data, trains and registers the SARIMA model, and (crucially)
#      grants the app's service principal permissions on all UC catalog/schema/table
#      assets, the Lakebase PostgreSQL database, and the model-serving endpoint.
#   5. `databricks apps deploy` — performs the final app deployment only after
#      all permissions are in place, so the app starts cleanly without
#      catalog-permission errors.
#
# app/_bundle_config.py is gitignored and re-generated on every deploy.

set -euo pipefail

# ── Minimum CLI version check ─────────────────────────────────────────────────
# postgres_projects/branches/endpoints resources require Databricks CLI >= 0.287.0.
_CLI_VER=$(databricks --version 2>/dev/null | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1 || echo "0.0.0")
_CLI_MAJOR=$(echo "$_CLI_VER" | cut -d. -f1)
_CLI_MINOR=$(echo "$_CLI_VER" | cut -d. -f2)
if [ "$_CLI_MAJOR" -lt 1 ] && [ "$_CLI_MINOR" -lt 287 ]; then
    echo "ERROR: Databricks CLI >= 0.287.0 required (found ${_CLI_VER})." >&2
    echo "       Install: https://docs.databricks.com/aws/en/dev-tools/cli/install" >&2
    exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BUNDLE_ARGS=("$@")

# ── Step 1: resolve variables and generate app/_bundle_config.py ─────────────
echo "==> Resolving bundle variables..."
VALIDATE_JSON=$(databricks bundle validate --output json "${BUNDLE_ARGS[@]}" 2>/dev/null)

CATALOG=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('catalog',{}).get('value','my_catalog'))")
SCHEMA=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('schema',{}).get('value','actuarial_workshop'))")
PG_DATABASE=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('pg_database',{}).get('value','actuarial_workshop_db'))")
ENDPOINT_NAME=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('variables',{}).get('endpoint_name',{}).get('value','actuarial-workshop-sarima-forecaster'))")

echo "==> Generating app/_bundle_config.py"
echo "    CATALOG=${CATALOG}, SCHEMA=${SCHEMA}, PG_DATABASE=${PG_DATABASE}, ENDPOINT_NAME=${ENDPOINT_NAME}"
# LAKEBASE_ENDPOINT_PATH is the resource name used for generate_database_credential
# and for the SDK API call that resolves the endpoint hostname at runtime.
# Format: projects/{project_id}/branches/{branch_id}/endpoints/{endpoint_id}
# These IDs match the resource definitions in resources/lakebase.yml.
LAKEBASE_ENDPOINT_PATH="projects/actuarial-workshop-lakebase/branches/main/endpoints/primary"
cat > "${SCRIPT_DIR}/app/_bundle_config.py" << EOF
# Auto-generated by deploy.sh — do not edit or commit
CATALOG = '${CATALOG}'
SCHEMA = '${SCHEMA}'
PG_DATABASE = '${PG_DATABASE}'
ENDPOINT_NAME = '${ENDPOINT_NAME}'
LAKEBASE_ENDPOINT_PATH = '${LAKEBASE_ENDPOINT_PATH}'
EOF

# Extract app name, workspace source path, and CLI profile from validate output.
APP_NAME=$(echo "$VALIDATE_JSON" \
    | python3 -c "
import sys, json
d = json.load(sys.stdin)
apps = d.get('resources', {}).get('apps', {})
print(list(apps.values())[0].get('name', '')) if apps else print('')
")
APP_SOURCE_PATH=$(echo "$VALIDATE_JSON" \
    | python3 -c "
import sys, json
d = json.load(sys.stdin)
apps = d.get('resources', {}).get('apps', {})
print(list(apps.values())[0].get('source_code_path', '')) if apps else print('')
")
PROFILE=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('workspace',{}).get('profile',''))")

PROFILE_ARGS=()
if [ -n "$PROFILE" ]; then
    PROFILE_ARGS=(--profile "$PROFILE")
fi

WORKSPACE_HOST=$(echo "$VALIDATE_JSON" \
    | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('workspace',{}).get('host',''))")

# ── Step 2: bundle deploy ─────────────────────────────────────────────────────
echo "==> Running databricks bundle deploy ${BUNDLE_ARGS[*]}"
databricks bundle deploy "${BUNDLE_ARGS[@]}"

# ── Step 2.5: Lakebase database setup (runs locally using CLI OAuth JWT) ──────
# Lakebase Autoscaling endpoints require standard OAuth JWTs for authentication.
# Internal Databricks cluster tokens (apiToken(), DATABRICKS_TOKEN on job compute)
# are opaque credentials rejected by Lakebase's databricks_auth extension.
# The local CLI provides a proper OAuth JWT, so we run setup here instead of
# from within the notebook.
if python3 -c "import psycopg2" 2>/dev/null; then
    # Get app SP client ID from the deployed app resource
    SP_CLIENT_ID=""
    if [ -n "$APP_NAME" ]; then
        SP_CLIENT_ID=$(databricks api get "/api/2.0/apps/${APP_NAME}" \
            "${PROFILE_ARGS[@]}" 2>/dev/null \
            | python3 -c "
import sys, json
lines = sys.stdin.read().split('\n')
j = next((i for i,l in enumerate(lines) if l.strip().startswith('{')), None)
if j is not None:
    d = json.loads('\n'.join(lines[j:]))
    print(d.get('service_principal_client_id', ''))
" 2>/dev/null || echo "")
    fi

    echo "==> Setting up Lakebase database (using local OAuth JWT)..."
    echo "    App SP client ID: ${SP_CLIENT_ID:-(not found)}"
    python3 "${SCRIPT_DIR}/scripts/lakebase_setup.py" \
        --workspace-host "${WORKSPACE_HOST}" \
        --endpoint-path  "${LAKEBASE_ENDPOINT_PATH}" \
        --pg-database    "${PG_DATABASE}" \
        --app-sp-client-id "${SP_CLIENT_ID}" \
        ${PROFILE:+--profile "$PROFILE"}
else
    echo "WARNING: psycopg2-binary not installed — skipping Lakebase setup."
    echo "         Install with: pip install psycopg2-binary"
    echo "         Then re-run deploy.sh to complete Lakebase setup."
fi

# ── Step 3: start app compute if needed ──────────────────────────────────────
# When bundle creates a fresh app it leaves compute STOPPED and queues an
# initial deployment internally. That deployment holds the deployment lock,
# permanently blocking our later `apps deploy` call. Starting the compute
# clears the lock without deploying anything, so step 5 can proceed cleanly.
if [ -n "$APP_NAME" ]; then
    COMPUTE_STATE=$(databricks api get "/api/2.0/apps/${APP_NAME}" \
        "${PROFILE_ARGS[@]}" 2>/dev/null \
        | python3 -c "
import sys, json
lines = sys.stdin.read().split('\n')
j = next((i for i,l in enumerate(lines) if l.strip().startswith('{')), None)
if j is not None:
    print(json.loads('\n'.join(lines[j:])).get('compute_status', {}).get('state', ''))
" 2>/dev/null || echo "")
    if [ "$COMPUTE_STATE" = "STOPPED" ]; then
        echo "==> App compute is STOPPED — starting it to clear bundle's initial deployment lock..."
        databricks apps start "${APP_NAME}" "${PROFILE_ARGS[@]}" > /dev/null 2>&1 || true
        echo "    App compute started."
    fi
fi

# ── Step 4: run setup job ─────────────────────────────────────────────────────
# This provisions all data assets and — critically — grants the app's service
# principal permissions on UC catalog/schema/tables, the Lakebase PostgreSQL
# database, and the model-serving endpoint. The app must not be deployed until
# this completes, otherwise it starts with missing permissions.
echo "==> Running setup job (this takes ~15 min)..."
databricks bundle run actuarial_workshop_setup "${BUNDLE_ARGS[@]}"

# ── Step 5: deploy app ────────────────────────────────────────────────────────
# All permissions are now in place. Deploy the app source code so it starts
# with a clean slate against the fully-provisioned, permissioned environment.
if [ -n "$APP_NAME" ] && [ -n "$APP_SOURCE_PATH" ]; then
    echo "==> Deploying app source code..."
    echo "    App:    ${APP_NAME}"
    echo "    Source: ${APP_SOURCE_PATH}"
    databricks apps deploy "${APP_NAME}" \
        --source-code-path "${APP_SOURCE_PATH}" \
        "${PROFILE_ARGS[@]}"
    echo "==> App deployment complete!"
else
    echo "==> No app found in bundle, skipping app deployment."
fi
