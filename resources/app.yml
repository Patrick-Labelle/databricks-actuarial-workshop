# ─── Databricks App: Actuarial Risk Dashboard ────────────────────────────────
# Streamlit application served via Databricks Apps (serverless, UC-integrated).
# Runtime configuration (env vars, command) lives in app/app.yaml and has
# bundle variables substituted at deploy time.

resources:
  apps:
    actuarial_workshop_app:
      name: "actuarial-workshop"
      source_code_path: ../app

      # ── Note on CATALOG / SCHEMA / PGDATABASE ────────────────────────────────
      # These cannot go in app/app.yaml (uploaded as-is, no ${var.*} substitution)
      # and the config.env block here is silently ignored by the Apps platform.
      # Instead, deploy.sh generates app/_bundle_config.py with the resolved values
      # before each deploy. The app imports _bundle_config.py at startup as a fallback.
      # Always deploy with ./deploy.sh, not bare `databricks bundle deploy`.

      # ── App resource authorizations ──────────────────────────────────────────
      # Each entry grants the app's service principal a specific permission on a
      # Databricks resource. Values are injected into the app at runtime via
      # valueFrom in app/app.yaml — no credentials are embedded in source code.
      resources:
        - name: sql-warehouse
          description: "SQL Warehouse for Statement Execution API (claims data queries)"
          sql_warehouse:
            id: "${var.warehouse_id}"
            permission: CAN_USE

        - name: serving-endpoint
          description: "SARIMA Claims Forecaster model serving endpoint"
          serving_endpoint:
            name: "${var.endpoint_name}"
            permission: CAN_QUERY

        - name: database
          description: "Lakebase (managed Postgres) for persistent scenario annotations"
          database:
            instance_name: "${resources.database_instances.actuarial_workshop_lakebase.name}"
            database_name: "${var.pg_database}"
            permission: CAN_CONNECT_AND_CREATE
