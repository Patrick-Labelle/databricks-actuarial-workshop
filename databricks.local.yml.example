# ─── LOCAL CONFIG TEMPLATE ────────────────────────────────────────────────────
# 1. Copy this file:  cp databricks.local.yml.example databricks.local.yml
# 2. Fill in your workspace-specific values below
# 3. Deploy:          ./deploy.sh --target my-workspace
#
# IMPORTANT: always use ./deploy.sh instead of `databricks bundle deploy` directly.
# deploy.sh generates app/_bundle_config.py with the resolved catalog/schema/pg_database
# values before deploying. Skipping it means the app will use hardcoded defaults.
#
# This file is auto-merged by the bundle (via the include glob in databricks.yml)
# and is gitignored to keep sensitive IDs/URLs out of version control.

targets:
  my-workspace:                                                   # ← rename this
    workspace:
      host: https://your-workspace.cloud.databricks.com          # ← replace
      profile: your-profile                                       # ← replace (from ~/.databrickscfg)
    variables:
      catalog: your_catalog                                       # ← replace (UC catalog, must exist)
      schema: actuarial_workshop
      endpoint_name: actuarial-workshop-sarima-forecaster
      warehouse_id: "your_warehouse_id"                           # ← replace (workspace SQL settings)
      pg_database: actuarial_workshop_db                          # ← Lakebase database name (provisioned by bundle)
      notification_email: your.email@example.com                 # ← optional
